{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3a201b",
   "metadata": {},
   "source": [
    "- Usage\n",
    "    - Basic\n",
    "    - Text prompts\n",
    "    - Message prompts\n",
    "    - Dictionary format\n",
    "- Message types\n",
    "    - System Message\n",
    "    - Human Message\n",
    "    - AI Message, \n",
    "    - Tool Message\n",
    "    - Streaming and chunks\n",
    "- Content\n",
    "    - Standard content blocks\n",
    "    - Multimodal\n",
    "- Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb0ef2",
   "metadata": {},
   "source": [
    "### 기본 사용법 (Basic Usage)\n",
    "메시지 객체를 생성하고 호출할 때 모델에 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f532a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "model = init_chat_model(\"openai:gpt-5-nano\")\n",
    "\n",
    "system_msg = SystemMessage(\"You are a helpful assistant.\")\n",
    "human_msg = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "# Use with chat models\n",
    "messages = [system_msg, human_msg]\n",
    "response = model.invoke(messages)  # Returns AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea7620",
   "metadata": {},
   "source": [
    "- 텍트스 프롬프트 (Text prompts)\n",
    "문자열이므로 대화 기록을 보관할 필요가 없는 간단한 생성 작업에 적합."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"Write a haiku about spring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d2d4e",
   "metadata": {},
   "source": [
    "- 메시지 프롬프트 (Message prompts)\n",
    "메시지 객체 목록을 제공하여 모델에 메시지 목록을 전달.\n",
    "여러 차례의 대화 관리, 다중 모드 콘텐츠(오디오, 이미지, 파일) 작업, 시스템 지침 포함 등에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a poetry expert\"),\n",
    "    HumanMessage(\"Write a haiku about spring\"),\n",
    "    AIMessage(\"Cherry blossoms bloom...\")\n",
    "]\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdbf3eb",
   "metadata": {},
   "source": [
    "- 사전 형식 (Dictionary prompts)\n",
    "OpenAI 채팅 완성 형식으로 메시지를 직접 지정할 수도 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetry expert\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about spring\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cherry blossoms bloom...\"}\n",
    "]\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e182586f",
   "metadata": {},
   "source": [
    "### Message types\n",
    " 시스템 메시지 - 모델이 상호 작용에 대한 컨텍스트를 제공하고 동작하는 방법을 알려줍니다.\n",
    " 인간 메시지 - 사용자 입력 및 모델과의 상호 작용을 나타냅니다.\n",
    " AI 메시지 - 텍스트 콘텐츠, 도구 호출, 메타데이터를 포함한 모델에서 생성된 응답\n",
    " 도구 메시지 - 도구 호출의 출력을 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8756cd04",
   "metadata": {},
   "source": [
    "- 시스템 메시지 (System Message)\n",
    "모델의 행동을 준비하는 초기 지침을 나타냄. 시스템 메시지를 사용하여 분위기를 설정하고, 모델의 역할을 정의하고, 응답 지침을 설정할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70002e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = SystemMessage(\"You are a helpful coding assistant.\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# 좀 더 자세한 지침\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_msg = SystemMessage(\"\"\"\n",
    "You are a senior Python developer with expertise in web frameworks.\n",
    "Always provide code examples and explain your reasoning.\n",
    "Be concise but thorough in your explanations.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"How do I create a REST API?\")\n",
    "]\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185192d9",
   "metadata": {},
   "source": [
    "- 인간의 메시지 (Human Message)\n",
    "사용자 입력과 상호작용을 나타냄. 텍스트, 이미지, 오디오, 파일 및 기타 다양한 멀티모달 콘텐츠를 포함할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2031b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_msg = HumanMessage(\"What is machine learning?\")\n",
    "response = model.invoke([human_msg])\n",
    "\n",
    "# 메시지 메타데이터\n",
    "human_msg = HumanMessage(\n",
    "    content=\"Hello!\",\n",
    "    name=\"alice\",  # Optional: identify different users\n",
    "    id=\"msg_123\",  # Optional: unique identifier for tracing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21deb07",
   "metadata": {},
   "source": [
    "- AI 메시지 (AI Message)\n",
    "모델 호출의 출력을 나타냄. 여기에는 나중에 엑세스할 수 있는 다중 모드 데이터, 도구 호출 및 공급자별 메타데이터가 포함될 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"Explain AI\")\n",
    "print(type(response))  # <class 'langchain_core.messages.AIMessage'>\n",
    "\n",
    "# 메뉴얼 AI 응답 메시지\n",
    "from langchain_core.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# Create an AI message manually (e.g., for conversation history)\n",
    "ai_msg = AIMessage(\"I'd be happy to help you with that question!\")\n",
    "\n",
    "# Add to conversation history\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Can you help me?\"),\n",
    "    ai_msg,  # Insert as if it came from the model\n",
    "    HumanMessage(\"Great! What's 2+2?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8789c7d",
   "metadata": {},
   "source": [
    "- 도구 호출 응답 (Tool Message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64738bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools([...])\n",
    "response = model_with_tools.invoke(\"What's the weather in Paris?\")\n",
    "\n",
    "for tool_call in response.tool_calls:\n",
    "    print(f\"Tool: {tool_call['name']}\")\n",
    "    print(f\"Args: {tool_call['args']}\")\n",
    "    print(f\"ID: {tool_call['id']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ac274",
   "metadata": {},
   "source": [
    "도구 호출을 지원하는 모델의 경우, AI 메시지에 도구 호출이 포함될 수 있음. 도구 메시지는 단일 도구 실행 결과를 모델로 다시 전달하는데 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "# After a model makes a tool call\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"args\": {\"location\": \"San Francisco\"},\n",
    "        \"id\": \"call_123\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Execute tool and create result message\n",
    "weather_result = \"Sunny, 72°F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # Must match the call ID\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "messages = [\n",
    "    HumanMessage(\"What's the weather in San Francisco?\"),\n",
    "    ai_message,  # Model's tool call\n",
    "    tool_message,  # Tool execution result\n",
    "]\n",
    "response = model.invoke(messages)  # Model processes the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65be0f7",
   "metadata": {},
   "source": [
    "- 스트리밍 및 청크 (Streaming and chunks)\n",
    "스트리밍하는 동안 결합할 수 있는 AIMessageChunk 객체를 받게 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for chunk in model.stream(\"Write a poem\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81421aeb",
   "metadata": {},
   "source": [
    "### 콘텐츠 (Content)\n",
    "메지니의 내용은 모델로 전송되는 데이터 페이로드라고 생각하면 됨. 메시지는 느슨한 타입의 속성을 가지며, 문자열과 타입이 지정되지 않은 객체 목록(예: Dictionary)를 지원함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97998399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 입력 모드. \n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# String content\n",
    "human_message = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "# Provider-native format (e.g., OpenAI)\n",
    "human_message = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image_url\", \"image_url\": {\"url\": \"https://example.com/image.jpg\"}}\n",
    "])\n",
    "\n",
    "# List of standard content blocks\n",
    "human_message = HumanMessage(content_blocks=[\n",
    "    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image\", \"url\": \"https://example.com/image.jpg\"},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683419fe",
   "metadata": {},
   "source": [
    "- 표준 메시지 블록 (Standard content blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "message = AIMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"reasoning\",\n",
    "            \"id\": \"rs_abc123\",\n",
    "            \"summary\": [\n",
    "                {\"type\": \"summary_text\", \"text\": \"summary 1\"},\n",
    "                {\"type\": \"summary_text\", \"text\": \"summary 2\"},\n",
    "            ],\n",
    "        },\n",
    "        {\"type\": \"text\", \"text\": \"...\", \"id\": \"msg_abc123\"},\n",
    "    ],\n",
    "    response_metadata={\"model_provider\": \"openai\"}\n",
    ")\n",
    "message.content_blocks\n",
    "# [{'type': 'reasoning', 'id': 'rs_abc123', 'reasoning': 'summary 1'},\n",
    "#  {'type': 'reasoning', 'id': 'rs_abc123', 'reasoning': 'summary 2'},\n",
    "#  {'type': 'text', 'text': '...', 'id': 'msg_abc123'}]\n",
    "\n",
    "# ---\n",
    "# Anthropic\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "message = AIMessage(\n",
    "    content=[\n",
    "        {\"type\": \"thinking\", \"thinking\": \"...\", \"signature\": \"WaUjzkyp...\"},\n",
    "        {\"type\": \"text\", \"text\": \"...\"},\n",
    "    ],\n",
    "    response_metadata={\"model_provider\": \"anthropic\"}\n",
    ")\n",
    "message.content_blocks\n",
    "# [{'type': 'reasoning',\n",
    "#   'reasoning': '...',\n",
    "#   'extras': {'signature': 'WaUjzkyp...'}},\n",
    "#  {'type': 'text', 'text': '...'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286469ba",
   "metadata": {},
   "source": [
    "- 멀티모달 (Multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e891af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From URL\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n",
    "        {\"type\": \"image\", \"url\": \"https://example.com/path/to/image.jpg\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# From base64 data\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"base64\": \"AAAAIGZ0eXBtcDQyAAAAAGlzb21tcDQyAAACAGlzb2...\",\n",
    "            \"mime_type\": \"image/jpeg\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "# From provider-managed File ID\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Describe the content of this image.\"},\n",
    "        {\"type\": \"image\", \"file_id\": \"file-abc123\"},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551f5749",
   "metadata": {},
   "source": [
    "### Example\n",
    "대화형 애플리케이션을 구축하려면 메시지 기록과 컨텍스트를 관리해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0654fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Initialize conversation\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant specializing in Python programming\")\n",
    "]\n",
    "\n",
    "# Simulate multi-turn conversation\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    # Add user message\n",
    "    messages.append(HumanMessage(user_input))\n",
    "\n",
    "    # Get model response\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # Add assistant response to history\n",
    "    messages.append(response)\n",
    "\n",
    "    print(f\"Assistant: {response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
