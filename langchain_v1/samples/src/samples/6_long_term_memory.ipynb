{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2c77ef1",
   "metadata": {},
   "source": [
    "### Long-term memory\n",
    "LangGraph는 장기 메모리를 JSON 으로 저장소에 저장함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe07e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "\n",
    "def embed(texts: list[str]) -> list[list[float]]:\n",
    "    # Replace with an actual embedding function or LangChain embeddings object\n",
    "    return [[1.0, 2.0] * len(texts)]\n",
    "\n",
    "\n",
    "# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.\n",
    "store = InMemoryStore(index={\"embed\": embed, \"dims\": 2})\n",
    "user_id = \"my-user\"\n",
    "application_context = \"chitchat\"\n",
    "namespace = (user_id, application_context)\n",
    "store.put(\n",
    "    namespace,\n",
    "    \"a-memory\",\n",
    "    {\n",
    "        \"rules\": [\n",
    "            \"User likes short, direct language\",\n",
    "            \"User only speaks English & python\",\n",
    "        ],\n",
    "        \"my-key\": \"my-value\",\n",
    "    },\n",
    ")\n",
    "# get the \"memory\" by ID\n",
    "item = store.get(namespace, \"a-memory\")\n",
    "# search for \"memories\" within this namespace, filtering on content equivalence, sorted by vector similarity\n",
    "items = store.search(\n",
    "    namespace, filter={\"my-key\": \"my-value\"}, query=\"language preferences\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012d19c",
   "metadata": {},
   "source": [
    "- Tool 에서 장기 기억 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbf62c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='look up user information', additional_kwargs={}, response_metadata={}, id='f5565603-5a32-440e-b57f-2836720655ea'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 276, 'prompt_tokens': 122, 'total_tokens': 398, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CGyLJIQv13KByB0pLCoBb3lDFIDm7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--4bd787dc-ff94-4915-8f37-f91db07d632a-0', tool_calls=[{'name': 'get_user_info', 'args': {}, 'id': 'call_8oOJgaPuasuGV0HJHtMAF0ZY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 122, 'output_tokens': 276, 'total_tokens': 398, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}}),\n",
       "  ToolMessage(content=\"{'name': 'John Smith', 'language': 'English'}\", name='get_user_info', id='531f2f22-ebbf-40e8-abaf-e13fd9fff56f', tool_call_id='call_8oOJgaPuasuGV0HJHtMAF0ZY'),\n",
       "  AIMessage(content='Here is the user information I found:\\n- Name: John Smith\\n- Language: English\\n\\nWould you like me to update any of these details or perform another action (e.g., fetch more profile data, set a preferred language, etc.)?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 315, 'prompt_tokens': 161, 'total_tokens': 476, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CGyLMoEa3ubCnEaeV32IAzd1L0laB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--ba81ec44-d524-4732-8ffa-45ecec682142-0', usage_metadata={'input_tokens': 161, 'output_tokens': 315, 'total_tokens': 476, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_store\n",
    "from langgraph.runtime import get_runtime\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "store = InMemoryStore() # (1)!\n",
    "\n",
    "store.put(  # (2)!\n",
    "    (\"users\",),  # (3)!\n",
    "    \"user_123\",  # (4)!\n",
    "    {\n",
    "        \"name\": \"John Smith\",\n",
    "        \"language\": \"English\",\n",
    "    } # (5)!\n",
    ")\n",
    "\n",
    "def get_user_info() -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    # Same as that provided to `create_agent`\n",
    "    store = get_runtime().store # (6)!\n",
    "    user_id = get_runtime(Context).context.user_id\n",
    "    user_info = store.get((\"users\",), user_id) # (7)!\n",
    "    return str(user_info.value) if user_info else \"Unknown user\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[get_user_info],\n",
    "    store=store, # (8)!\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"look up user information\"}]},\n",
    "    context=Context(user_id=\"user_123\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ac453",
   "metadata": {},
   "source": [
    "- Tool 에서 장기 메모리 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07135eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Smith'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_store\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "store = InMemoryStore() # (1)!\n",
    "\n",
    "class UserInfo(TypedDict): # (2)!\n",
    "    name: str\n",
    "\n",
    "def save_user_info(user_info: UserInfo, config: RunnableConfig) -> str: # (3)!\n",
    "    \"\"\"Save user info.\"\"\"\n",
    "    # Same as that provided to `create_agent`\n",
    "    store = get_store() # (4)!\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    store.put((\"users\",), user_id, user_info) # (5)!\n",
    "    return \"Successfully saved user info.\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[save_user_info],\n",
    "    store=store\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is John Smith. Save my information\"}]},\n",
    "    config={\"configurable\": {\"user_id\": \"user_123\"}} # (6)!\n",
    ")\n",
    "\n",
    "# You can access the store directly to get the value\n",
    "store.get((\"users\",), \"user_123\").value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
