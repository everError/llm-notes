{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239e6be5",
   "metadata": {},
   "source": [
    "- Agnet\n",
    "    - static agent\n",
    "    - dynamic agent\n",
    "- Tools\n",
    "    - ToolNode\n",
    "- Prompt\n",
    "    - string\n",
    "    - SystemMessage\n",
    "    - Callable\n",
    "- Structured Output\n",
    "- Memory\n",
    "    - Messagte State\n",
    "- Pre-model hook\n",
    "- Post-model hook\n",
    "- Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b9e15e",
   "metadata": {},
   "source": [
    "### Agent\n",
    "에이전트는 언어 모델과 도구를 결합하여 작업에 대해 추론하고, 어떤 도구를 사용할지 결정하고, 반복적으로 솔루션을 향애 노력하는 시스템을 만듭니다.\n",
    "\n",
    "`create_agent() 논문  'ReAct: Synergizing Reasoning and Acting in Language Models'를 기반으로 한 프로덕션에 바로 적용 가능한 ReAct(추론 + 행동) 에이전트 구현을 제공합니다.\n",
    "\n",
    "---\n",
    "\n",
    "ReAct \n",
    "`thought` 단계: 에이전트의 행동을 여러 `action`, `observation` 단계의 교차로 구성\n",
    "모델은 추론을 작성하고, 도구를 선택하고, 도구 결과를 확인한 후 이를 반복.\n",
    "\n",
    "에이전트는 가설을 세우고(`thought`), 도구를 사용하여 검증하고 (`action`), 피드백을 기반으로 계획을 업데이트(`observation`) 함.\n",
    "\n",
    "ReAct 루프는 정지 조건(모델이 최종 답변을 내보내거나 최대 반복 횟수 제한에 도달할 때)에 도달할 때까지 실행."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1922ca",
   "metadata": {},
   "source": [
    "## 정적 모델 (Static model)\n",
    "생성할 때 한번만 구성되며 실행 과정 내내 변경되지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace82de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "tools = []\n",
    "agent = create_agent(\n",
    "    \"openai:gpt-5\",\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29986d",
   "metadata": {},
   "source": [
    "`runtime` 에이전트의 실행 환경. 에이전트 실행 기간 내내 유지되는 변경 불가능한 구성과 상황적 데이터(예: 사용자 ID, 세션 세부 정보 또는 애플리케이션별 구성)을 포함.\n",
    "\n",
    "`state`: 메시지, 사용자 정의 필드, 처리 중에 추적하고 잠재적으로 수정해야 하는 모든 정보(예: 사용자 기본 설정 또는 도구 사용 통계)를 포함하여 에이전트 실행을 통해 흐르는 데이터.\n",
    "\n",
    "## 동적 모델(Dynamic model)\n",
    "현재 상태와 컨텍스트를 기반으로 런타임에 선택. 이를 통해 정교한 라우팅 로직과 비용 최적화가 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "def select_model(state: AgentState, runtime: Runtime) -> ChatOpenAI:\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    message_count = len(messages)\n",
    "\n",
    "    if message_count < 10:\n",
    "        return ChatOpenAI(model=\"gpt-4.1-mini\").bind_tools(tools)\n",
    "    else:\n",
    "        return ChatOpenAI(model=\"gpt-5\").bind_tools(tools) # Better model for longer conversations\n",
    "\n",
    "agent = create_agent(select_model, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fcfb60",
   "metadata": {},
   "source": [
    "## 도구 (Tools)\n",
    "에이전트에게 조취를 취할 수 있는 능력을 제공. 에이전트는 다음과 같은 기능을 통해 단순한 모델 기반 도구 바인딩을 넘어섬.\n",
    "- 단일 프롬프트에 의해 트리거되는 시퀀스의 여러 도구 호출\n",
    "- 적절한 경우 병렬 도구 호출\n",
    "- 결과에 따른 동적 도구 선택\n",
    "- 도구 재시도 논리 및 오류 처리\n",
    "- 도구 호출에 따른 상태 지속성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bf33f0",
   "metadata": {},
   "source": [
    "case 1. 도구 목록을 에이전트에 전달하면 ToolNode가 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e718d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Perform calculations.\"\"\"\n",
    "    return str(eval(expression))\n",
    "\n",
    "agent = create_agent(model, tools=[search, calculate])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75170c22",
   "metadata": {},
   "source": [
    "case 2. 구성된 ToolNode 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c08043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ToolNode\n",
    "\n",
    "tool_node = ToolNode(\n",
    "    tools=[search, calculate],\n",
    "    handle_tool_errors=\"Please check your input and try again.\"\n",
    ")\n",
    "agent = create_agent(model, tools=tool_node)\n",
    "result = agent.invoke({\"messages\": [...]})\n",
    "\n",
    "# 오류가 발생하면 사용자 지정 오류 메시지와 함께 모델에 반환\n",
    "# result[\"messages\"]\n",
    "# [\n",
    "#     ...\n",
    "#     ToolMessage(content=\"Please check your input and try again.\", tool_call_id=\"...\"),\n",
    "#     ...\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b90817",
   "metadata": {},
   "source": [
    "## 프롬프트 (Prompt)\n",
    "제공 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "# String 제공\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    prompt=\"You are a helpful assistant. Be concise and accurate.\"\n",
    ")\n",
    "# SystemMessage 제공\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    prompt=SystemMessage(content=\"You are a research assistant. Cite your sources.\")\n",
    ")\n",
    "# Callable\n",
    "def dynamic_prompt(state):\n",
    "    user_type = state.get(\"user_type\", \"standard\")\n",
    "    system_msg = SystemMessage(\n",
    "        content=\"Provide detailed technical responses.\"\n",
    "            if user_type == \"expert\"\n",
    "            else \"Provide simple, clear explanations.\"\n",
    "    )\n",
    "    return [system_msg] + state[\"messages\"]\n",
    "agent = create_agent(model, tools, prompt=dynamic_prompt)\n",
    "\n",
    "# prompt가 제공되지 않으면 에이전트는 메시지에서 직접 작업을 추론."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55dd648",
   "metadata": {},
   "source": [
    "## 구조화된 출력 (Structured Output)\n",
    "    `response_format` 매개변수를 사용하여 이를 수행할 수 있는 방법을 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae578588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[...],\n",
    "    response_format=ContactInfo\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]\n",
    "# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10869927",
   "metadata": {},
   "source": [
    "## 메모리 (Memory)\n",
    "메시지 상태를 통해 대화 기록을 자동 관리. 사용자 지정 상태 스키마를 사용하여 대화 중 추가 정보를 기억하도록 구성할 수도 있음.\n",
    "상태(Messagte State)에 저장된 정보는 에이전트의 \"단기 메모리\"로 생각할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b5d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated # 기존 타입 힌트에 부가적인 정보(메타데이터)를 추가\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents import AgentState\n",
    "\n",
    "class CustomAgentState(AgentState):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_preferences: dict\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    state_schema=CustomAgentState\n",
    ")\n",
    "\n",
    "# The agent can now track additional state beyond messages. \n",
    "# This custom state can be accessed and updated throughout the conversation.\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"I prefer technical explanations\"}],\n",
    "    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88146df2",
   "metadata": {},
   "source": [
    "## Pre-model hook\n",
    "모델이 호출되기 전에 상태를 처리할 수 있는 선택적 노드.\n",
    "메시지 트리밍, 요약, 컨텍스트 주입 등에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cdcc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langchain.agents import create_agent\n",
    "# 컨텍스트 창에 맞게 메시지를 잘라내는 사전 모델 hook 예시\n",
    "# {\n",
    "#     # Will UPDATE the `messages` in the state\n",
    "#     \"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES), ...],\n",
    "#     # Any other state keys that need to be propagated\n",
    "#     ...\n",
    "# }\n",
    "def trim_messages(state):\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return {\"messages\": messages}\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "# If you are returning messages in the pre-model hook, \n",
    "# you should OVERWRITE the messages key by doing the following:\n",
    "# {\n",
    "# \"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES), *new_messages]\n",
    "# ...\n",
    "# }\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages # *: Iterable Unpacking\n",
    "        ]\n",
    "    }\n",
    "# my_list = [2, 3, 4]\n",
    "\n",
    "# # my_list를 언패킹하여 새로운 리스트를 생성\n",
    "# new_list = [1, *my_list, 5]\n",
    "\n",
    "# # 위 코드는 아래와 동일하게 동작합니다.\n",
    "# # new_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "# print(new_list)\n",
    "# # 출력: [1, 2, 3, 4, 5]\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    pre_model_hook=trim_messages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d3e7f8",
   "metadata": {},
   "source": [
    "## Post-model hook\n",
    "모델 후처리, 도구 실행 전에 모델의 응답을 처리할 수 있는 선택적 노드\n",
    "* 후처리 이후 도구 호출을 하거나, 응답 전송\n",
    "\n",
    "검증, 가드레인 또는 기타 hook 처리에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ddeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "# 기밀 정보를 걸러내는 포스트 모델 후크의 예:\n",
    "def validate_response(state):\n",
    "    \"\"\"Check model response for policy violations.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    if \"confidential\" in last_message.content.lower():\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "                *messages[:-1],\n",
    "                AIMessage(content=\"I cannot share confidential information.\")\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    return {}\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    post_model_hook=validate_response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3f4088",
   "metadata": {},
   "source": [
    "## 스트리밍 (Streaming)\n",
    "에이전트가 여러 단계를 실행하는 경우 시간이 걸릴 수 있음. 준간 진행 상황을 보여주기 위해\n",
    "메시지가 발생하는 대로 스트리밍할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7701c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in agent.stream({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Search for AI news and summarize the findings\"}]\n",
    "}, stream_mode=\"values\"):\n",
    "    # Each chunk contains the full state at that point\n",
    "    latest_message = chunk[\"messages\"][-1]\n",
    "    if latest_message.content:\n",
    "        print(f\"Agent: {latest_message.content}\")\n",
    "    elif latest_message.tool_calls:\n",
    "        print(f\"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
