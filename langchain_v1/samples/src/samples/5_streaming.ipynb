{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0398c8a2",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "스트리밍은 LLM 기반 애플리케이션의 응답성을 향상시키는데 매우 중요합니다. 완전한 응답이 준비되기 전에도 출력을 점진적으로 표시함으로써 스트리밍은 사용자 경험(UX)을 크게 향상시키며, 특히 LLM의 지연 시간을 처리할 때 더욱 그렇습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f486b1e",
   "metadata": {},
   "source": [
    "- 에이전트 진행 상황과 함께 스크리밍 하려면 \n",
    "`stream()`, 또는 `astream()` 메소드 사용, `stream_mode=\"update\"`로 하면 이이전트의 모든 단계가 끝날 때마다 이벤트가 발생."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129ffbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: agent\n",
      "content: [{'type': 'tool_call', 'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_ouzVPlu0WHuAWk71mzQUzH8C'}]\n",
      "step: tools\n",
      "content: [{'type': 'text', 'text': \"It's always sunny in San Francisco!\"}]\n",
      "step: agent\n",
      "content: [{'type': 'text', 'text': \"San Francisco weather: It's always sunny in San Francisco!\\n\\nIf you’d like exact details (temperature, wind, humidity, hourly forecast), I can pull those up.\"}]\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for step, data in chunk.items():\n",
    "        print(f\"step: {step}\")\n",
    "        print(f\"content: {data['messages'][-1].content_blocks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a2480",
   "metadata": {},
   "source": [
    "- LLM에서 생성된 토큰을 스트리밍 하려면 `stream_mode=\"message\"로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a67576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: agent\n",
      "content: [{'type': 'tool_call_chunk', 'id': 'call_dGegzHKCgwyrMz7aD8zq6tDj', 'name': 'get_weather', 'args': '', 'index': 0}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '{\"', 'index': 0}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'city', 'index': 0}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '\":\"', 'index': 0}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': 'San', 'index': 0}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': ' Francisco', 'index': 0}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'tool_call_chunk', 'id': None, 'name': None, 'args': '\"}', 'index': 0}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: []\n",
      "\n",
      "\n",
      "node: tools\n",
      "content: [{'type': 'text', 'text': \"It's always sunny in San Francisco!\"}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: []\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': 'It'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': '’s'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' always'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' sunny'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' in'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' San'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' Francisco'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': '!\\n\\n'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': 'If'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' you'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': '’d'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' like'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' real'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': '-time'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' conditions'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' or'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' a'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' forecast'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' ('}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': 'temperature'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' wind'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' precipitation'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': '),'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' I'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' can'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' fetch'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' that'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' next'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' Which'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' details'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' would'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' you'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': ' like'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: [{'type': 'text', 'text': '?'}]\n",
      "\n",
      "\n",
      "node: agent\n",
      "content: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"node: {metadata['langgraph_node']}\")\n",
    "    print(f\"content: {token.content_blocks}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092fb7e6",
   "metadata": {},
   "source": [
    "- 도구가 실행되면서 업데이트를 스트리밍하려면 `get_stream_writer`를 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74481d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up data for city: San Francisco\n",
      "Acquired data for city: San Francisco\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=\"custom\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bfeee6",
   "metadata": {},
   "source": [
    "- `stream_mode=[\"updates\", \"custom\"]` 스트림 모드를 목록으로 전달하여 여러 모드를 지원할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0f6077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream_mode: updates\n",
      "content: {'agent': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 216, 'prompt_tokens': 132, 'total_tokens': 348, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CGyEa8AKXAieMh0UrMu5q8pib9wM7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--d6f712d4-8f76-469e-8fd1-ba7fb9a307b6-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_MboQ06dAgPa1cae2q64lrZtf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 216, 'total_tokens': 348, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})]}}\n",
      "\n",
      "\n",
      "stream_mode: custom\n",
      "content: Looking up data for city: San Francisco\n",
      "\n",
      "\n",
      "stream_mode: custom\n",
      "content: Acquired data for city: San Francisco\n",
      "\n",
      "\n",
      "stream_mode: updates\n",
      "content: {'tools': {'messages': [ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', tool_call_id='call_MboQ06dAgPa1cae2q64lrZtf')]}}\n",
      "\n",
      "\n",
      "stream_mode: updates\n",
      "content: {'agent': {'messages': [AIMessage(content=\"San Francisco weather: It's always sunny in San Francisco!\\n\\nIf you’d like more details (temperature, humidity, wind, etc.), I can fetch them.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 488, 'prompt_tokens': 168, 'total_tokens': 656, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CGyEdG7JoJuC8pK8v2jimdaBuIX4N', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--1f23edf7-2d73-4e3f-a104-6b186b0ce6a0-0', usage_metadata={'input_tokens': 168, 'output_tokens': 488, 'total_tokens': 656, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}})]}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for stream_mode, chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"updates\", \"custom\"]\n",
    "):\n",
    "    print(f\"stream_mode: {stream_mode}\")\n",
    "    print(f\"content: {chunk}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
