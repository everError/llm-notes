# Few-Shot Prompting 개요

## 🔍 Few-Shot Prompting이란?

Few-Shot Prompting은 언어 모델(Large Language Model, LLM)에 작업 예시를 몇 개 제공함으로써, 별도의 파인튜닝 없이 모델이 유사한 작업을 수행하도록 유도하는 프롬프팅 기법입니다. 이 접근 방식은 모델이 작업 패턴을 예시로부터 학습하고, 그 패턴을 일반화하여 새로운 입력에 적용할 수 있도록 돕습니다.

- "Few"는 보통 1~5개 수준의 예시를 의미합니다.
- 모델의 매개변수(parameter)는 바뀌지 않고, **입력 프롬프트에 예시 데이터를 포함**시키는 방식입니다.

---

## 🧠 작동 원리

LLM은 입력된 텍스트의 순서를 따라 확률적으로 다음 토큰을 예측하는 방식으로 작동합니다. Few-Shot Prompting에서는 다음과 같은 형식으로 예시와 실제 질문을 함께 프롬프트로 제공합니다:

```
Q: 고양이는 어떤 동물인가요?
A: 고양이는 작고 털이 있으며 독립적인 성격을 가진 반려동물입니다.

Q: 코끼리는 어떤 동물인가요?
A: 코끼리는 크고 귀가 크며 똑똑한 초식동물입니다.

Q: 돌고래는 어떤 동물인가요?
A:
```

→ 이 경우, 모델은 이전 예시들을 통해 문장 스타일과 답변 형식을 학습한 뒤, 돌고래에 대한 설명을 유추합니다.

---

## ✅ 특징과 장점

| 특징              | 설명                                          |
| ----------------- | --------------------------------------------- |
| 파인튜닝 불필요   | 사전 학습된 모델에 추가 학습 없이 사용 가능   |
| 유연성            | 다양한 작업에 적용 가능 (번역, 분류, 요약 등) |
| 빠른 프로토타이핑 | 빠르게 작업 유형 테스트 가능                  |
| 인간 친화적       | 사람처럼 예시 기반 학습 수행                  |

---

## 🚫 한계점

- **예시 수에 민감**: 예시가 너무 적거나 부적절할 경우 성능 저하
- **컨텍스트 길이 제한**: 프롬프트에 많은 예시를 넣을 수 없음 (모델의 입력 토큰 제한에 의해 제약)
- **일관성 부족**: 동일한 입력에 대해서도 다양한 응답을 생성할 수 있음
- **메모리 기반 학습 한계**: 실제 파인튜닝처럼 장기 기억을 가지지 않음

---

## 🧪 Few-Shot vs Zero-Shot vs One-Shot

| 구분      | 설명                       | 예시 수  |
| --------- | -------------------------- | -------- |
| Zero-Shot | 예시 없이 작업 지시만 제공 | 0        |
| One-Shot  | 하나의 예시만 제공         | 1        |
| Few-Shot  | 여러 개의 예시 제공        | 보통 2~5 |

예시:

- **Zero-Shot**: "이 문장을 영어로 번역해줘: 나는 학생입니다."
- **One-Shot**:

  ```
  한국어: 안녕하세요
  영어: Hello

  한국어: 나는 학생입니다.
  영어:
  ```

- **Few-Shot**:

  ```
  한국어: 안녕하세요
  영어: Hello

  한국어: 오늘 날씨 어때요?
  영어: How's the weather today?

  한국어: 나는 학생입니다.
  영어:
  ```

---

## 🛠 사용 팁

1. **예시의 질**: 고품질, 명확한 예시를 사용하세요.
2. **작업 일관성 유지**: 모든 예시는 같은 작업 유형과 형식을 따르도록 구성하세요.
3. **토큰 한계 고려**: 너무 긴 예시보다는 간결하고 대표적인 예시를 선택하세요.
4. **최근 예시 우선**: LLM은 프롬프트의 끝 부분에 더 큰 가중치를 둘 수 있음 → 중요한 예시는 마지막에 배치

---
